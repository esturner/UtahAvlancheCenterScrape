{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3871927b-f3b5-438e-bc49-3f4823e9fef1",
   "metadata": {},
   "source": [
    "# Utah Avalanch Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67fdcb-b936-4461-af21-f94030ca6725",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b025d5-f35f-4489-9106-c33095fea1a6",
   "metadata": {},
   "source": [
    "## Starting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb65d18-473b-4efc-9c9f-05c0a00e48ca",
   "metadata": {},
   "source": [
    "The initial idea is to draw out each avalanche/conditions observation and log that in a table of observations or catalog. Each observation in the catalog holds whatever data that observer reports (weather, tests, descriptions, avalanche, etc). First we need to try doing this for the first page of observations in this year 2023. Then we match observations to forcasts and see if we can't get some avalanche data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d27fbbd-e623-47a3-a145-97d572b7d93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from bs4 import BeautifulSoup\n",
    "pd.__version__ #need version>=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e9b9f2-d4d8-476e-af57-1d2a4a0bf52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etran\\Anaconda3\\python.exe\n",
      "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]\n",
      "sys.version_info(major=3, minor=9, micro=16, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023825d2-b647-4549-b516-bd6f4cb92b67",
   "metadata": {},
   "source": [
    "I got some good infor on converting html files into pandas dataframes from this article, https://towardsdatascience.com/how-to-get-tables-from-websites-into-pandas-dataframes-e82bd8a0ac59. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76fde28d-fddd-4d5f-8764-aa041d135881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Date, None)</th>\n",
       "      <th>(Region, None)</th>\n",
       "      <th>(, None)</th>\n",
       "      <th>(Observer, None)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2/9/2023, None)</td>\n",
       "      <td>(Salt Lake, None)</td>\n",
       "      <td>(Observation: White Pine, /observation/75011)</td>\n",
       "      <td>(Gagne, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2/9/2023, None)</td>\n",
       "      <td>(Uintas, None)</td>\n",
       "      <td>(Observation: Mill Hollow, /observation/75013)</td>\n",
       "      <td>(Gordon, Manship, Collett, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2/9/2023, None)</td>\n",
       "      <td>(Salt Lake, None)</td>\n",
       "      <td>(Observation: Toots to Boot, /observation/75012)</td>\n",
       "      <td>(Meisenheimer / Staples, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2/9/2023, None)</td>\n",
       "      <td>(Provo, None)</td>\n",
       "      <td>(Observation: North Fork, /observation/75000)</td>\n",
       "      <td>(Josh Martineau, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2/9/2023, None)</td>\n",
       "      <td>(Uintas, None)</td>\n",
       "      <td>(Avalanche: Tower Mountain, /avalanche/75010)</td>\n",
       "      <td>(Gordon, Manship, Collett, None)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       (Date, None)     (Region, None)  \\\n",
       "0  (2/9/2023, None)  (Salt Lake, None)   \n",
       "1  (2/9/2023, None)     (Uintas, None)   \n",
       "2  (2/9/2023, None)  (Salt Lake, None)   \n",
       "3  (2/9/2023, None)      (Provo, None)   \n",
       "4  (2/9/2023, None)     (Uintas, None)   \n",
       "\n",
       "                                           (, None)  \\\n",
       "0     (Observation: White Pine, /observation/75011)   \n",
       "1    (Observation: Mill Hollow, /observation/75013)   \n",
       "2  (Observation: Toots to Boot, /observation/75012)   \n",
       "3     (Observation: North Fork, /observation/75000)   \n",
       "4     (Avalanche: Tower Mountain, /avalanche/75010)   \n",
       "\n",
       "                   (Observer, None)  \n",
       "0                     (Gagne, None)  \n",
       "1  (Gordon, Manship, Collett, None)  \n",
       "2    (Meisenheimer / Staples, None)  \n",
       "3            (Josh Martineau, None)  \n",
       "4  (Gordon, Manship, Collett, None)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://utahavalanchecenter.org/observations'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "tbl = soup.find(\"table\")\n",
    "#print(tbl.dtype)\n",
    "page_obs = pd.read_html(str(tbl),extract_links ='all')[0] #extract link so we can take a closer look at the observation\n",
    "page_obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07faf85a-a868-4030-a1d3-cc2f0e76b5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://utahavalanchecenter.org/observation/75011\n",
      "The fields are ['Observation Date', 'Observer Name', 'Region', 'Location Name or Route', 'Sky', 'Weather Comments', 'New Snow Depth', 'New Snow Density', 'Snow Surface Conditions', 'Snow Characteristics Comments', 'Red Flags', 'Problem', 'Trend', 'Problem #1 Comments', 'Comments', \"Today's Observed Danger Rating\", 'Tomorrows Estimated Danger Rating', 'Coordinates']\n",
      "['2/9/2023', 'Gagne', 'Salt Lake » Little Cottonwood Canyon » White Pine', 'White Pine', 'Clear', 'Calm winds.', '2\"', 'Low', 'Powder', 'Wind Crust', \"Wind effect was most evident in exposed alpine terrain above about 9,500'. \", 'Recent Avalanches', 'Wind Loading', 'Wind Drifted Snow', 'Decreasing Danger', 'The strong winds on Wednesday created pockets of wind-drifted snow on all aspects at the upper elevations. The drifts were generally only 5-15 cms thick, but some were up to 30 cms thick.', None, None, None, None, None, None, None, 'Moderate', 'Moderate', None]\n"
     ]
    }
   ],
   "source": [
    "extension = page_obs.iloc[0,2][1]\n",
    "url = 'http://utahavalanchecenter.org' + extension\n",
    "print(url)\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#print(soup)\n",
    "fields = []\n",
    "for section in soup.find_all(attrs={'class':\"field-label text_02 bold mb0\"}):\n",
    "    fields.append(section.string)\n",
    "data = []\n",
    "for section in soup.find_all(attrs={'class':\"text_02 mb2\"}):\n",
    "    data.append(section.string)\n",
    "print('The fields are', fields)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25b0a1-2b19-40dc-bd19-0bc7620113f9",
   "metadata": {},
   "source": [
    "One problem with this data is that there are some categories such as Red Flags that have multiple entries. Looking at the observation report page (https://utahavalanchecenter.org/node/add/observations) there are up to 7 possible red flags and spaces to name up to two avalanche problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0dde6-44e9-42a8-88ec-35960046ed2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
