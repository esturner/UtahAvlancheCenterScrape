{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3871927b-f3b5-438e-bc49-3f4823e9fef1",
   "metadata": {},
   "source": [
    "# Utah Avalanch Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67fdcb-b936-4461-af21-f94030ca6725",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b025d5-f35f-4489-9106-c33095fea1a6",
   "metadata": {},
   "source": [
    "## Starting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb65d18-473b-4efc-9c9f-05c0a00e48ca",
   "metadata": {},
   "source": [
    "The initial idea is to draw out each avalanche/conditions observation and log that in a table of observations or catalog. Each observation in the catalog holds whatever data that observer reports (weather, tests, descriptions, avalanche, etc). First we need to try doing this for the first page of observations in this year 2023. Then we match observations to forcasts and see if we can't get some avalanche data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d27fbbd-e623-47a3-a145-97d572b7d93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from bs4 import BeautifulSoup\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023825d2-b647-4549-b516-bd6f4cb92b67",
   "metadata": {},
   "source": [
    "I got some good infor on converting html files into pandas dataframes from this article, https://towardsdatascience.com/how-to-get-tables-from-websites-into-pandas-dataframes-e82bd8a0ac59. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5e0709-3f71-428f-bf5c-510044a823b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pd.read_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76fde28d-fddd-4d5f-8764-aa041d135881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Date, None)</th>\n",
       "      <th>(Region, None)</th>\n",
       "      <th>(, None)</th>\n",
       "      <th>(Observer, None)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2/18/2023, None)</td>\n",
       "      <td>(Logan, None)</td>\n",
       "      <td>(Observation: Logan Peak Area, /observation/75...</td>\n",
       "      <td>(Jake Lyman &amp; Ellie Ward, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2/18/2023, None)</td>\n",
       "      <td>(Moab, None)</td>\n",
       "      <td>(Observation: Moab, /observation/75408)</td>\n",
       "      <td>(Nauman, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2/18/2023, None)</td>\n",
       "      <td>(Salt Lake, None)</td>\n",
       "      <td>(Observation: Mill Creek Canyon, /observation/...</td>\n",
       "      <td>(Gagne, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2/18/2023, None)</td>\n",
       "      <td>(Provo, None)</td>\n",
       "      <td>(Observation: UFO Bowls, /observation/75412)</td>\n",
       "      <td>(T Diegel, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2/18/2023, None)</td>\n",
       "      <td>(Provo, None)</td>\n",
       "      <td>(Observation: Mt Nebo Loop Road, /observation/...</td>\n",
       "      <td>(Raylund Smith, None)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        (Date, None)     (Region, None)  \\\n",
       "0  (2/18/2023, None)      (Logan, None)   \n",
       "1  (2/18/2023, None)       (Moab, None)   \n",
       "2  (2/18/2023, None)  (Salt Lake, None)   \n",
       "3  (2/18/2023, None)      (Provo, None)   \n",
       "4  (2/18/2023, None)      (Provo, None)   \n",
       "\n",
       "                                            (, None)  \\\n",
       "0  (Observation: Logan Peak Area, /observation/75...   \n",
       "1            (Observation: Moab, /observation/75408)   \n",
       "2  (Observation: Mill Creek Canyon, /observation/...   \n",
       "3       (Observation: UFO Bowls, /observation/75412)   \n",
       "4  (Observation: Mt Nebo Loop Road, /observation/...   \n",
       "\n",
       "                  (Observer, None)  \n",
       "0  (Jake Lyman & Ellie Ward, None)  \n",
       "1                   (Nauman, None)  \n",
       "2                    (Gagne, None)  \n",
       "3                 (T Diegel, None)  \n",
       "4            (Raylund Smith, None)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://utahavalanchecenter.org/observations'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "tbl = soup.find(\"table\")\n",
    "#print(tbl.dtype)\n",
    "page_obs = pd.read_html(str(tbl),extract_links ='all')[0]\n",
    "page_obs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e113840-a65f-41af-ae9d-f6344c903cf3",
   "metadata": {},
   "source": [
    "The main problem with the extract_links is it converts everying into a tuple. We want to eliminate the tuples and rewrite the \"(,None)\" column as \"link_extensions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a168f00-7c3f-4bf5-9eed-53d6b4df8865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f1b53-393c-4bbc-9e19-033cc744be94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
